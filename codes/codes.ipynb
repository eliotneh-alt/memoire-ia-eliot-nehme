{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "636eab23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eliot.nehme\\repositories\\memoire-ia\\codes\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "459cc21c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ComputeError",
     "evalue": "could not parse `\"2B\"` as dtype `i64` at column 'DEPT' (column number 6)\n\nThe current offset in the file is 16420 bytes.\n\nYou might want to try:\n- increasing `infer_schema_length` (e.g. `infer_schema_length=10000`),\n- specifying correct dtype with the `schema_overrides` argument\n- setting `ignore_errors` to `True`,\n- adding `\"2B\"` to the `null_values` list.\n\nOriginal error: ```invalid primitive value found during CSV parsing```",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mComputeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# On définit explicitement que DEPT est du texte\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m table_souscription = \u001b[43mpl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mDonnes_souscription.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(table_souscription)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\eliot.nehme\\AppData\\Local\\Python\\pythoncore-3.14-64\\Lib\\site-packages\\polars\\_utils\\deprecation.py:128\u001b[39m, in \u001b[36mdeprecate_renamed_parameter.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    123\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(function)\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args: P.args, **kwargs: P.kwargs) -> T:\n\u001b[32m    125\u001b[39m     _rename_keyword_argument(\n\u001b[32m    126\u001b[39m         old_name, new_name, kwargs, function.\u001b[34m__qualname__\u001b[39m, version\n\u001b[32m    127\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\eliot.nehme\\AppData\\Local\\Python\\pythoncore-3.14-64\\Lib\\site-packages\\polars\\_utils\\deprecation.py:128\u001b[39m, in \u001b[36mdeprecate_renamed_parameter.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    123\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(function)\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args: P.args, **kwargs: P.kwargs) -> T:\n\u001b[32m    125\u001b[39m     _rename_keyword_argument(\n\u001b[32m    126\u001b[39m         old_name, new_name, kwargs, function.\u001b[34m__qualname__\u001b[39m, version\n\u001b[32m    127\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\eliot.nehme\\AppData\\Local\\Python\\pythoncore-3.14-64\\Lib\\site-packages\\polars\\_utils\\deprecation.py:128\u001b[39m, in \u001b[36mdeprecate_renamed_parameter.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    123\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(function)\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args: P.args, **kwargs: P.kwargs) -> T:\n\u001b[32m    125\u001b[39m     _rename_keyword_argument(\n\u001b[32m    126\u001b[39m         old_name, new_name, kwargs, function.\u001b[34m__qualname__\u001b[39m, version\n\u001b[32m    127\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\eliot.nehme\\AppData\\Local\\Python\\pythoncore-3.14-64\\Lib\\site-packages\\polars\\io\\csv\\functions.py:551\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(source, has_header, columns, new_columns, separator, comment_prefix, quote_char, skip_rows, skip_lines, schema, schema_overrides, null_values, missing_utf8_is_empty_string, ignore_errors, try_parse_dates, n_threads, infer_schema, infer_schema_length, batch_size, n_rows, encoding, low_memory, rechunk, use_pyarrow, storage_options, skip_rows_after_header, row_index_name, row_index_offset, sample_size, eol_char, raise_if_empty, truncate_ragged_lines, decimal_comma, glob)\u001b[39m\n\u001b[32m    543\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    544\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m prepare_file_arg(\n\u001b[32m    545\u001b[39m         source,\n\u001b[32m    546\u001b[39m         encoding=encoding,\n\u001b[32m   (...)\u001b[39m\u001b[32m    549\u001b[39m         storage_options=storage_options,\n\u001b[32m    550\u001b[39m     ) \u001b[38;5;28;01mas\u001b[39;00m data:\n\u001b[32m--> \u001b[39m\u001b[32m551\u001b[39m         df = \u001b[43m_read_csv_impl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    552\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    553\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhas_header\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_header\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    554\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprojection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    555\u001b[39m \u001b[43m            \u001b[49m\u001b[43mseparator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseparator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    556\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcomment_prefix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcomment_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    557\u001b[39m \u001b[43m            \u001b[49m\u001b[43mquote_char\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquote_char\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    558\u001b[39m \u001b[43m            \u001b[49m\u001b[43mskip_rows\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskip_rows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    559\u001b[39m \u001b[43m            \u001b[49m\u001b[43mskip_lines\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskip_lines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    560\u001b[39m \u001b[43m            \u001b[49m\u001b[43mschema_overrides\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschema_overrides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    561\u001b[39m \u001b[43m            \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    562\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnull_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnull_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    563\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmissing_utf8_is_empty_string\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmissing_utf8_is_empty_string\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    564\u001b[39m \u001b[43m            \u001b[49m\u001b[43mignore_errors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_errors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    565\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtry_parse_dates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtry_parse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    566\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[43m            \u001b[49m\u001b[43minfer_schema_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43minfer_schema_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    568\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    569\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_rows\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_rows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    570\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf8-lossy\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    571\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlow_memory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlow_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    572\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrechunk\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrechunk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    573\u001b[39m \u001b[43m            \u001b[49m\u001b[43mskip_rows_after_header\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskip_rows_after_header\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    574\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrow_index_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrow_index_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    575\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrow_index_offset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrow_index_offset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    576\u001b[39m \u001b[43m            \u001b[49m\u001b[43meol_char\u001b[49m\u001b[43m=\u001b[49m\u001b[43meol_char\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    577\u001b[39m \u001b[43m            \u001b[49m\u001b[43mraise_if_empty\u001b[49m\u001b[43m=\u001b[49m\u001b[43mraise_if_empty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    578\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtruncate_ragged_lines\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtruncate_ragged_lines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    579\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdecimal_comma\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecimal_comma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    580\u001b[39m \u001b[43m            \u001b[49m\u001b[43mglob\u001b[49m\u001b[43m=\u001b[49m\u001b[43mglob\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    581\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    583\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m new_columns:\n\u001b[32m    584\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _update_columns(df, new_columns)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\eliot.nehme\\AppData\\Local\\Python\\pythoncore-3.14-64\\Lib\\site-packages\\polars\\io\\csv\\functions.py:699\u001b[39m, in \u001b[36m_read_csv_impl\u001b[39m\u001b[34m(source, has_header, columns, separator, comment_prefix, quote_char, skip_rows, skip_lines, schema, schema_overrides, null_values, missing_utf8_is_empty_string, ignore_errors, try_parse_dates, n_threads, infer_schema_length, batch_size, n_rows, encoding, low_memory, rechunk, skip_rows_after_header, row_index_name, row_index_offset, sample_size, eol_char, raise_if_empty, truncate_ragged_lines, decimal_comma, glob)\u001b[39m\n\u001b[32m    695\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m    697\u001b[39m projection, columns = parse_columns_arg(columns)\n\u001b[32m--> \u001b[39m\u001b[32m699\u001b[39m pydf = \u001b[43mPyDataFrame\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    700\u001b[39m \u001b[43m    \u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    701\u001b[39m \u001b[43m    \u001b[49m\u001b[43minfer_schema_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    703\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhas_header\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    704\u001b[39m \u001b[43m    \u001b[49m\u001b[43mignore_errors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_rows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    706\u001b[39m \u001b[43m    \u001b[49m\u001b[43mskip_rows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    707\u001b[39m \u001b[43m    \u001b[49m\u001b[43mskip_lines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    708\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprojection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseparator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    710\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrechunk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    711\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    712\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    713\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    714\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    715\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    716\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype_slice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    717\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlow_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    718\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcomment_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    719\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquote_char\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprocessed_null_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    721\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmissing_utf8_is_empty_string\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    722\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtry_parse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    723\u001b[39m \u001b[43m    \u001b[49m\u001b[43mskip_rows_after_header\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    724\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparse_row_index_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow_index_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow_index_offset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    725\u001b[39m \u001b[43m    \u001b[49m\u001b[43meol_char\u001b[49m\u001b[43m=\u001b[49m\u001b[43meol_char\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    726\u001b[39m \u001b[43m    \u001b[49m\u001b[43mraise_if_empty\u001b[49m\u001b[43m=\u001b[49m\u001b[43mraise_if_empty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    727\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtruncate_ragged_lines\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtruncate_ragged_lines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    728\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecimal_comma\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecimal_comma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    729\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    730\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    731\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m wrap_df(pydf)\n",
      "\u001b[31mComputeError\u001b[39m: could not parse `\"2B\"` as dtype `i64` at column 'DEPT' (column number 6)\n\nThe current offset in the file is 16420 bytes.\n\nYou might want to try:\n- increasing `infer_schema_length` (e.g. `infer_schema_length=10000`),\n- specifying correct dtype with the `schema_overrides` argument\n- setting `ignore_errors` to `True`,\n- adding `\"2B\"` to the `null_values` list.\n\nOriginal error: ```invalid primitive value found during CSV parsing```"
     ]
    }
   ],
   "source": [
    "# On définit explicitement que DEPT est du texte\n",
    "table_souscription = pl.read_csv(\"Donnes_souscription.csv\")\n",
    "\n",
    "print(table_souscription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56f4a5d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions : (108653, 27)\n",
      "shape: (5, 27)\n",
      "┌─────┬─────────────────┬───────────────────┬─────────────────┬───┬─────┬─────┬─────┬─────┐\n",
      "│     ┆ num_police      ┆ date_debut_police ┆ date_fin_police ┆ … ┆ 2   ┆ 3   ┆ 4   ┆ 5   │\n",
      "│ --- ┆ ---             ┆ ---               ┆ ---             ┆   ┆ --- ┆ --- ┆ --- ┆ --- │\n",
      "│ i64 ┆ i64             ┆ str               ┆ str             ┆   ┆ f64 ┆ f64 ┆ f64 ┆ i64 │\n",
      "╞═════╪═════════════════╪═══════════════════╪═════════════════╪═══╪═════╪═════╪═════╪═════╡\n",
      "│ 2   ┆ 201000000000002 ┆ 2010-08-26        ┆ 2011-08-26      ┆ … ┆ 0.0 ┆ 0.0 ┆ 0.0 ┆ 0   │\n",
      "│ 8   ┆ 201000000000008 ┆ 2010-03-22        ┆ 2011-03-22      ┆ … ┆ 0.0 ┆ 0.0 ┆ 0.0 ┆ 0   │\n",
      "│ 54  ┆ 201000000000054 ┆ 2010-07-06        ┆ 2011-07-06      ┆ … ┆ 0.0 ┆ 0.0 ┆ 0.0 ┆ 0   │\n",
      "│ 56  ┆ 201000000000056 ┆ 2010-05-13        ┆ 2011-05-13      ┆ … ┆ 0.0 ┆ 0.0 ┆ 0.0 ┆ 0   │\n",
      "│ 71  ┆ 201000000000071 ┆ 2010-02-24        ┆ 2011-02-24      ┆ … ┆ 0.0 ┆ 0.0 ┆ 0.0 ┆ 0   │\n",
      "└─────┴─────────────────┴───────────────────┴─────────────────┴───┴─────┴─────┴─────┴─────┘\n"
     ]
    }
   ],
   "source": [
    "# avant de décider du type de chaque colonne. \n",
    "# C'est un peu plus lent (quelques secondes), mais c'est 100% sûr.\n",
    "\n",
    "table_souscription = pl.read_csv(\n",
    "    \"../data/Donnees_souscription.csv\", \n",
    "    infer_schema_length=None  # <--- Le secret est là !\n",
    ")\n",
    "\n",
    "print(f\"Dimensions : {table_souscription.shape}\") # Affiche le nombre de lignes/colonnes\n",
    "print(table_souscription.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a4599ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a292497e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0       num_police date_debut_police date_fin_police  REGION DEPT  \\\n",
      "0           2  201000000000002        2010-08-26      2011-08-26      52   72   \n",
      "1           8  201000000000008        2010-03-22      2011-03-22      11   77   \n",
      "2          54  201000000000054        2010-07-06      2011-07-06      52   85   \n",
      "3          56  201000000000056        2010-05-13      2011-05-13      76   66   \n",
      "4          71  201000000000071        2010-02-24      2011-02-24      75   79   \n",
      "\n",
      "  COMMUNE     CRITAIR                       ENERGIE  AGE_VOIT  ... TRANS GARL  \\\n",
      "0   72341  Crit'air 3                       Essence        10  ...     5    1   \n",
      "1   77235  Crit'air 2                        Gazole         5  ...     6    1   \n",
      "2   85226  Crit'air 1  Essence hybride rechargeable         0  ...     5    2   \n",
      "3   66190  Crit'air 3                       Essence        16  ...     Z    2   \n",
      "4   79249  Crit'air 2                        Gazole        16  ...     5    1   \n",
      "\n",
      "   N_COND  ANCIENNETE  N_SINISTRE    1    2    3    4  5  \n",
      "0       3           9           0  0.0  0.0  0.0  0.0  0  \n",
      "1       2           1           0  0.0  0.0  0.0  0.0  0  \n",
      "2       2           0           0  0.0  0.0  0.0  0.0  0  \n",
      "3       3          15           0  0.0  0.0  0.0  0.0  0  \n",
      "4       3           7           0  0.0  0.0  0.0  0.0  0  \n",
      "\n",
      "[5 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/Donnees_souscription.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8dd111ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e6c682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de lignes après explosion (doit correspondre au nombre total de sinistres) : 12349\n",
      "\n",
      "--- Aperçu de la nouvelle table table_sinistres ---\n",
      "         num_police  N_SINISTRE date_debut_police DATE_SINISTRE  COUT_SINISTRE\n",
      "0   201000000000077           1        2010-09-26    2010-11-07         375.78\n",
      "1   201000000000287           1        2010-03-12    2010-12-31        6406.20\n",
      "2   201000000000321           1        2010-11-05    2011-06-30         103.98\n",
      "3   201000000000395           1        2010-10-28    2011-08-21        1159.46\n",
      "4   201000000000419           1        2010-01-17    2010-01-24        1078.37\n",
      "..              ...         ...               ...           ...            ...\n",
      "95  201000000012791           1        2010-01-06    2010-02-16         675.11\n",
      "96  201000000012835           1        2010-04-03    2011-01-30         519.35\n",
      "97  201000000012945           1        2010-07-11    2011-02-02        1199.19\n",
      "98  201000000013028           1        2010-11-16    2011-08-27         998.78\n",
      "99  201000000013064           1        2010-03-20    2010-11-03         280.87\n",
      "\n",
      "[100 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Chargement de la base de données\n",
    "# J'utilise le chemin vers ton fichier CSV\n",
    "df = pd.read_csv('../data/Donnees_souscription.csv')\n",
    "\n",
    "# --- ÉTAPE 1 : Filtrer et Exploser la base ---\n",
    "\n",
    "# On ne garde que les lignes ayant au moins 1 sinistre\n",
    "# Note : la colonne dans le CSV est \"N_SINISTRE\" (singulier)\n",
    "table_sinistres = df[df['N_SINISTRE'] > 0].copy()\n",
    "\n",
    "# On \"explose\" la table : on duplique les lignes selon la valeur de N_SINISTRE\n",
    "# Si N_SINISTRE = 2, la ligne est répétée 2 fois\n",
    "table_sinistres = table_sinistres.loc[table_sinistres.index.repeat(table_sinistres['N_SINISTRE'])].reset_index(drop=True)\n",
    "\n",
    "print(f\"Nombre de lignes après explosion (doit correspondre au nombre total de sinistres) : {len(table_sinistres)}\")\n",
    "\n",
    "# --- ÉTAPE 2 : Simulation Actuarielle ---\n",
    "\n",
    "# Conversion des colonnes dates en format datetime si ce n'est pas déjà fait\n",
    "table_sinistres['date_debut_police'] = pd.to_datetime(table_sinistres['date_debut_police'])\n",
    "table_sinistres['date_fin_police'] = pd.to_datetime(table_sinistres['date_fin_police'])\n",
    "\n",
    "# 1. Simulation du COUT_SINISTRE (Loi Log-Normale)\n",
    "# Paramètres de la loi normale sous-jacente (mu et sigma)\n",
    "# Ces valeurs (mu=7, sigma=1.5) sont des exemples standards pour obtenir des montants réalistes.\n",
    "# Tu peux les ajuster selon la sévérité moyenne désirée.\n",
    "mu = 7.0\n",
    "sigma = 1.5\n",
    "\n",
    "# Génération des coûts aléatoires\n",
    "table_sinistres['COUT_SINISTRE'] = np.random.lognormal(mean=mu, sigma=sigma, size=len(table_sinistres))\n",
    "\n",
    "# Arrondi à 2 décimales pour faire \"monétaire\"\n",
    "table_sinistres['COUT_SINISTRE'] = table_sinistres['COUT_SINISTRE'].round(2)\n",
    "\n",
    "# 2. Simulation de la DATE_SINISTRE (Aléatoire entre date_debut et date_fin)\n",
    "# Calcul de la durée de couverture en jours pour chaque ligne\n",
    "duree_couverture = (table_sinistres['date_fin_police'] - table_sinistres['date_debut_police']).dt.days\n",
    "\n",
    "# Génération d'un nombre de jours aléatoire entre 0 et la durée de couverture\n",
    "jours_aleatoires = np.random.randint(0, duree_couverture + 1, size=len(table_sinistres))\n",
    "\n",
    "# Ajout de ces jours à la date de début pour obtenir la date du sinistre\n",
    "table_sinistres['DATE_SINISTRE'] = table_sinistres['date_debut_police'] + pd.to_timedelta(jours_aleatoires, unit='D')\n",
    "\n",
    "# --- Affichage et Vérification ---\n",
    "print(\"\\n--- Aperçu de la nouvelle table table_sinistres ---\")\n",
    "print(table_sinistres[['num_police', 'N_SINISTRE', 'date_debut_police', 'DATE_SINISTRE', 'COUT_SINISTRE']].head(100))\n",
    "\n",
    "# Sauvegarde optionnelle\n",
    "# table_sinistres.to_csv('data/table_sinistres_generee.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- ÉTAPE 3 : Injection de la Fraude et Association des Images ---\n",
    "\n",
    "# 1. Définition des chemins vers tes images (Ceux de ton projet TER)\n",
    "# J'ai repris les chemins de ton PDF, vérifie qu'ils sont toujours bons sur ton PC !\n",
    "path_true_images = r\"C:\\Users\\jules\\OneDrive\\Documents\\ISFA 2A\\2eme semestre\\TER\\Data\\CrashedCar\\True data\"\n",
    "path_fake_images = r\"C:\\Users\\jules\\OneDrive\\Documents\\ISFA 2A\\2eme semestre\\TER\\Data\\CrashedCar\\Fake data\"\n",
    "\n",
    "# Petite sécurité : on vérifie si les dossiers existent, sinon on met un message\n",
    "if not os.path.exists(path_true_images):\n",
    "    print(f\"ATTENTION : Le dossier {path_true_images} est introuvable. Vérifie le chemin.\")\n",
    "    images_reelles_dispo = []\n",
    "else:\n",
    "    # On liste tous les fichiers images (jpg, png) dans le dossier\n",
    "    images_reelles_dispo = [f for f in os.listdir(path_true_images) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "if not os.path.exists(path_fake_images):\n",
    "    print(f\"ATTENTION : Le dossier {path_fake_images} est introuvable.\")\n",
    "    images_fake_dispo = []\n",
    "else:\n",
    "    images_fake_dispo = [f for f in os.listdir(path_fake_images) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "\n",
    "# 2. Simulation de la Fraude\n",
    "# On décide arbitrairement qu'il y a 5% de fraudeurs dans les sinistres\n",
    "# 0 = Honnête, 1 = Fraudeur\n",
    "table_sinistres['IS_FRAUD'] = np.random.choice([0, 1], size=len(table_sinistres), p=[0.95, 0.05])\n",
    "\n",
    "\n",
    "# 3. La fonction magique qui associe l'image\n",
    "def get_image_path(is_fraud):\n",
    "    # Si le dossier est vide ou introuvable, on met \"Image_Manquante\"\n",
    "    if is_fraud == 1:\n",
    "        if not images_fake_dispo: return \"Image_Manquante\"\n",
    "        # On pioche une image au hasard dans le dossier \"Fake\"\n",
    "        nom_image = random.choice(images_fake_dispo)\n",
    "        # On retourne le chemin complet\n",
    "        return os.path.join(path_fake_images, nom_image)\n",
    "    else:\n",
    "        if not images_reelles_dispo: return \"Image_Manquante\"\n",
    "        # On pioche une image au hasard dans le dossier \"True\"\n",
    "        nom_image = random.choice(images_reelles_dispo)\n",
    "        return os.path.join(path_true_images, nom_image)\n",
    "\n",
    "# On applique cette fonction ligne par ligne pour créer la colonne lien\n",
    "# C'est ici que la fusion opère !\n",
    "table_sinistres['CHEMIN_IMAGE'] = table_sinistres['IS_FRAUD'].apply(get_image_path)\n",
    "\n",
    "# --- Résultat Final ---\n",
    "print(\"\\n--- Aperçu Final avec Images ---\")\n",
    "# On regarde les colonnes intéressantes\n",
    "print(table_sinistres[['num_police', 'COUT_SINISTRE', 'IS_FRAUD', 'CHEMIN_IMAGE']].head())\n",
    "\n",
    "# On sauvegarde ce fichier \"Hybride\" pour la suite de ton mémoire\n",
    "table_sinistres.to_csv('base_sinistres_hybride.csv', index=False)\n",
    "print(\"\\nBase sauvegardée sous 'base_sinistres_hybride.csv'. C'est elle que ton IA va lire !\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
